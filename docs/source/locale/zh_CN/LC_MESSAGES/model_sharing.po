# SOME DESCRIPTIVE TITLE.
# Copyright (C) 2020, The Hugging Face Team, Licenced under the Apache
# License, Version 2.0
# This file is distributed under the same license as the transformers
# package.
# FIRST AUTHOR <EMAIL@ADDRESS>, 2021.
#
#, fuzzy
msgid ""
msgstr ""
"Project-Id-Version: transformers \n"
"Report-Msgid-Bugs-To: \n"
"POT-Creation-Date: 2021-07-30 16:44+0800\n"
"PO-Revision-Date: YEAR-MO-DA HO:MI+ZONE\n"
"Last-Translator: FULL NAME <EMAIL@ADDRESS>\n"
"Language-Team: LANGUAGE <LL@li.org>\n"
"MIME-Version: 1.0\n"
"Content-Type: text/plain; charset=utf-8\n"
"Content-Transfer-Encoding: 8bit\n"
"Generated-By: Babel 2.8.0\n"

#: ../../source/model_sharing.rst:14
msgid "Model sharing and uploading"
msgstr ""

#: ../../source/model_sharing.rst:16
msgid ""
"In this page, we will show you how to share a model you have trained or "
"fine-tuned on new data with the community on the `model hub "
"<https://huggingface.co/models>`__."
msgstr ""

#: ../../source/model_sharing.rst:27
msgid ""
"You will need to create an account on `huggingface.co "
"<https://huggingface.co/join>`__ for this."
msgstr ""

#: ../../source/model_sharing.rst:29
msgid "Optionally, you can join an existing organization or create a new one."
msgstr ""

#: ../../source/model_sharing.rst:32
msgid ""
"We have seen in the :doc:`training tutorial <training>`: how to fine-tune"
" a model on a given task. You have probably done something similar on "
"your task, either using the model directly in your own training loop or "
"using the "
":class:`~.transformers.Trainer`/:class:`~.transformers.TFTrainer` class. "
"Let's see how you can share the result on the `model hub "
"<https://huggingface.co/models>`__."
msgstr ""

#: ../../source/model_sharing.rst:38
msgid "Model versioning"
msgstr ""

#: ../../source/model_sharing.rst:40
msgid ""
"Since version v3.5.0, the model hub has built-in model versioning based "
"on git and git-lfs. It is based on the paradigm that one model *is* one "
"repo."
msgstr ""

#: ../../source/model_sharing.rst:43
msgid "This allows:"
msgstr ""

#: ../../source/model_sharing.rst:45
msgid "built-in versioning"
msgstr ""

#: ../../source/model_sharing.rst:46
msgid "access control"
msgstr ""

#: ../../source/model_sharing.rst:47
msgid "scalability"
msgstr ""

#: ../../source/model_sharing.rst:49
msgid ""
"This is built around *revisions*, which is a way to pin a specific "
"version of a model, using a commit hash, tag or branch."
msgstr ""

#: ../../source/model_sharing.rst:52
msgid "For instance:"
msgstr ""

#: ../../source/model_sharing.rst:63
msgid "Push your model from Python"
msgstr ""

#: ../../source/model_sharing.rst:66
msgid "Preparation"
msgstr ""

#: ../../source/model_sharing.rst:68
msgid ""
"The first step is to make sure your credentials to the hub are stored "
"somewhere. This can be done in two ways. If you have access to a "
"terminal, you cam just run the following command in the virtual "
"environment where you installed ðŸ¤— Transformers:"
msgstr ""

#: ../../source/model_sharing.rst:76
msgid ""
"It will store your access token in the Hugging Face cache folder (by "
"default :obj:`~/.cache/`)."
msgstr ""

#: ../../source/model_sharing.rst:78
msgid ""
"If you don't have an easy access to a terminal (for instance in a Colab "
"session), you can find a token linked to your acount by going on "
"`huggingface.co <https://huggingface.co/>`, click on your avatar on the "
"top left corner, then on `Edit profile` on the left, just beneath your "
"profile picture. In the submenu `API Tokens`, you will find your API "
"token that you can just copy."
msgstr ""

#: ../../source/model_sharing.rst:84
msgid "Directly push your model to the hub"
msgstr ""

#: ../../source/model_sharing.rst:92
msgid ""
"Once you have an API token (either stored in the cache or copied and "
"pasted in your notebook), you can directly push a finetuned model you "
"saved in :obj:`save_drectory` by calling:"
msgstr ""

#: ../../source/model_sharing.rst:99
msgid ""
"If you have your API token not stored in the cache, you will need to pass"
" it with :obj:`use_auth_token=your_token`. This is also be the case for "
"all the examples below, so we won't mention it again."
msgstr ""

#: ../../source/model_sharing.rst:102
msgid ""
"This will create a repository in your namespace name :obj:`my-awesome-"
"model`, so anyone can now run:"
msgstr ""

#: ../../source/model_sharing.rst:110
msgid ""
"Even better, you can combine this push to the hub with the call to "
":obj:`save_pretrained`:"
msgstr ""

#: ../../source/model_sharing.rst:116
msgid ""
"If you are a premium user and want your model to be private, just add "
":obj:`private=True` to this call."
msgstr ""

#: ../../source/model_sharing.rst:118
msgid ""
"If you are a member of an organization and want to push it inside the "
"namespace of the organization instead of yours, just add "
":obj:`organization=my_amazing_org`."
msgstr ""

#: ../../source/model_sharing.rst:122
msgid "Add new files to your model repo"
msgstr ""

#: ../../source/model_sharing.rst:124
msgid ""
"Once you have pushed your model to the hub, you might want to add the "
"tokenizer, or a version of your model for another framework (TensorFlow, "
"PyTorch, Flax). This is super easy to do! Let's begin with the tokenizer."
" You can add it to the repo you created before like this"
msgstr ""

#: ../../source/model_sharing.rst:132
msgid ""
"If you know its URL (it should be "
":obj:`https://huggingface.co/username/repo_name`), you can also do:"
msgstr ""

#: ../../source/model_sharing.rst:138
msgid ""
"And that's all there is to it! It's also a very easy way to fix a mistake"
" if one of the files online had a bug."
msgstr ""

#: ../../source/model_sharing.rst:140
msgid ""
"To add a model for another backend, it's also super easy. Let's say you "
"have fine-tuned a TensorFlow model and want to add the pytorch model "
"files to your model repo, so that anyone in the community can use it. The"
" following allows you to directly create a PyTorch version of your "
"TensorFlow model:"
msgstr ""

#: ../../source/model_sharing.rst:150
msgid ""
"You can also replace :obj:`save_directory` by the identifier of your "
"model (:obj:`username/repo_name`) if you don't have a local save of it "
"anymore. Then, just do the same as before:"
msgstr ""

#: ../../source/model_sharing.rst:157
msgid "or"
msgstr ""

#: ../../source/model_sharing.rst:165
msgid "Use your terminal and git"
msgstr ""

#: ../../source/model_sharing.rst:174
msgid "Basic steps"
msgstr ""

#: ../../source/model_sharing.rst:176
msgid ""
"In order to upload a model, you'll need to first create a git repo. This "
"repo will live on the model hub, allowing users to clone it and you (and "
"your organization members) to push to it."
msgstr ""

#: ../../source/model_sharing.rst:179
msgid ""
"You can create a model repo directly from `the /new page on the website "
"<https://huggingface.co/new>`__."
msgstr ""

#: ../../source/model_sharing.rst:181
msgid ""
"Alternatively, you can use the ``transformers-cli``. The next steps "
"describe that process:"
msgstr ""

#: ../../source/model_sharing.rst:183
msgid ""
"Go to a terminal and run the following command. It should be in the "
"virtual environment where you installed ðŸ¤— Transformers, since that "
"command :obj:`transformers-cli` comes from the library."
msgstr ""

#: ../../source/model_sharing.rst:191
msgid ""
"Once you are logged in with your model hub credentials, you can start "
"building your repositories. To create a repo:"
msgstr ""

#: ../../source/model_sharing.rst:197
msgid ""
"If you want to create a repo under a specific organization, you should "
"add a `--organization` flag:"
msgstr ""

#: ../../source/model_sharing.rst:203
msgid "This creates a repo on the model hub, which can be cloned."
msgstr ""

#: ../../source/model_sharing.rst:213
msgid ""
"When you have your local clone of your repo and lfs installed, you can "
"then add/remove from that clone as you would with any other git repo."
msgstr ""

#: ../../source/model_sharing.rst:223
msgid ""
"We are intentionally not wrapping git too much, so that you can go on "
"with the workflow you're used to and the tools you already know."
msgstr ""

#: ../../source/model_sharing.rst:226
msgid ""
"The only learning curve you might have compared to regular git is the one"
" for git-lfs. The documentation at `git-lfs.github.com <https://git-"
"lfs.github.com/>`__ is decent, but we'll work on a tutorial with some "
"tips and tricks in the coming weeks!"
msgstr ""

#: ../../source/model_sharing.rst:230
msgid ""
"Additionally, if you want to change multiple repos at once, the "
"`change_config.py script "
"<https://github.com/huggingface/efficient_scripts/blob/main/change_config.py>`__"
" can probably save you some time."
msgstr ""

#: ../../source/model_sharing.rst:234
msgid "Make your model work on all frameworks"
msgstr ""

#: ../../source/model_sharing.rst:239
msgid ""
"You probably have your favorite framework, but so will other users! "
"That's why it's best to upload your model with both PyTorch `and` "
"TensorFlow checkpoints to make it easier to use (if you skip this step, "
"users will still be able to load your model in another framework, but it "
"will be slower, as it will have to be converted on the fly). Don't worry,"
" it's super easy to do (and in a future version, it might all be "
"automatic). You will need to install both PyTorch and TensorFlow for this"
" step, but you don't need to worry about the GPU, so it should be very "
"easy. Check the `TensorFlow installation page "
"<https://www.tensorflow.org/install/pip#tensorflow-2.0-rc-is-"
"available>`__ and/or the `PyTorch installation page <https://pytorch.org"
"/get-started/locally/#start-locally>`__ to see how."
msgstr ""

#: ../../source/model_sharing.rst:247
msgid ""
"First check that your model class exists in the other framework, that is "
"try to import the same model by either adding or removing TF. For "
"instance, if you trained a "
":class:`~transformers.DistilBertForSequenceClassification`, try to type"
msgstr ""

#: ../../source/model_sharing.rst:254
msgid ""
"and if you trained a "
":class:`~transformers.TFDistilBertForSequenceClassification`, try to type"
msgstr ""

#: ../../source/model_sharing.rst:260
msgid ""
"This will give back an error if your model does not exist in the other "
"framework (something that should be pretty rare since we're aiming for "
"full parity between the two frameworks). In this case, skip this and go "
"to the next step."
msgstr ""

#: ../../source/model_sharing.rst:263
msgid ""
"Now, if you trained your model in PyTorch and have to create a TensorFlow"
" version, adapt the following code to your model class:"
msgstr ""

#: ../../source/model_sharing.rst:271
msgid ""
"and if you trained your model in TensorFlow and have to create a PyTorch "
"version, adapt the following code to your model class:"
msgstr ""

#: ../../source/model_sharing.rst:279
msgid "That's all there is to it!"
msgstr ""

#: ../../source/model_sharing.rst:282
msgid "Check the directory before pushing to the model hub."
msgstr ""

#: ../../source/model_sharing.rst:284
msgid ""
"Make sure there are no garbage files in the directory you'll upload. It "
"should only have:"
msgstr ""

#: ../../source/model_sharing.rst:286
msgid ""
"a `config.json` file, which saves the :doc:`configuration "
"<main_classes/configuration>` of your model ;"
msgstr ""

#: ../../source/model_sharing.rst:287
msgid ""
"a `pytorch_model.bin` file, which is the PyTorch checkpoint (unless you "
"can't have it for some reason) ;"
msgstr ""

#: ../../source/model_sharing.rst:288
msgid ""
"a `tf_model.h5` file, which is the TensorFlow checkpoint (unless you "
"can't have it for some reason) ;"
msgstr ""

#: ../../source/model_sharing.rst:289
msgid ""
"a `special_tokens_map.json`, which is part of your :doc:`tokenizer "
"<main_classes/tokenizer>` save;"
msgstr ""

#: ../../source/model_sharing.rst:290
msgid ""
"a `tokenizer_config.json`, which is part of your :doc:`tokenizer "
"<main_classes/tokenizer>` save;"
msgstr ""

#: ../../source/model_sharing.rst:291
msgid ""
"files named `vocab.json`, `vocab.txt`, `merges.txt`, or similar, which "
"contain the vocabulary of your tokenizer, part of your :doc:`tokenizer "
"<main_classes/tokenizer>` save;"
msgstr ""

#: ../../source/model_sharing.rst:293
msgid ""
"maybe a `added_tokens.json`, which is part of your :doc:`tokenizer "
"<main_classes/tokenizer>` save."
msgstr ""

#: ../../source/model_sharing.rst:295
msgid "Other files can safely be deleted."
msgstr ""

#: ../../source/model_sharing.rst:299
msgid "Uploading your files"
msgstr ""

#: ../../source/model_sharing.rst:301
msgid ""
"Once the repo is cloned, you can add the model, configuration and "
"tokenizer files. For instance, saving the model and tokenizer files:"
msgstr ""

#: ../../source/model_sharing.rst:309
msgid "Or, if you're using the Trainer API"
msgstr ""

#: ../../source/model_sharing.rst:316
msgid ""
"You can then add these files to the staging environment and verify that "
"they have been correctly staged with the ``git status`` command:"
msgstr ""

#: ../../source/model_sharing.rst:324
msgid "Finally, the files should be committed:"
msgstr ""

#: ../../source/model_sharing.rst:330
msgid "And pushed to the remote:"
msgstr ""

#: ../../source/model_sharing.rst:336
msgid ""
"This will upload the folder containing the weights, tokenizer and "
"configuration we have just prepared."
msgstr ""

#: ../../source/model_sharing.rst:340
msgid "Add a model card"
msgstr ""

#: ../../source/model_sharing.rst:342
msgid ""
"To make sure everyone knows what your model can do, what its limitations,"
" potential bias or ethical considerations are, please add a README.md "
"model card to your model repo. You can just create it, or there's also a "
"convenient button titled \"Add a README.md\" on your model page. A model "
"card template can be found `here "
"<https://github.com/huggingface/model_card>`__ (meta-suggestions are "
"welcome). model card template (meta-suggestions are welcome)."
msgstr ""

#: ../../source/model_sharing.rst:350
msgid ""
"Model cards used to live in the ðŸ¤— Transformers repo under `model_cards/`,"
" but for consistency and scalability we migrated every model card from "
"the repo to its corresponding huggingface.co model repo."
msgstr ""

#: ../../source/model_sharing.rst:353
msgid ""
"If your model is fine-tuned from another model coming from the model hub "
"(all ðŸ¤— Transformers pretrained models do), don't forget to link to its "
"model card so that people can fully trace how your model was built."
msgstr ""

#: ../../source/model_sharing.rst:358
msgid "Using your model"
msgstr ""

#: ../../source/model_sharing.rst:360
msgid "Your model now has a page on huggingface.co/models ðŸ”¥"
msgstr ""

#: ../../source/model_sharing.rst:362
msgid "Anyone can load it from code:"
msgstr ""

#: ../../source/model_sharing.rst:370
msgid ""
"You may specify a revision by using the ``revision`` flag in the "
"``from_pretrained`` method:"
msgstr ""

#: ../../source/model_sharing.rst:380
msgid "Workflow in a Colab notebook"
msgstr ""

#: ../../source/model_sharing.rst:382
msgid ""
"If you're in a Colab notebook (or similar) with no direct access to a "
"terminal, here is the workflow you can use to upload your model. You can "
"execute each one of them in a cell by adding a ! at the beginning."
msgstr ""

#: ../../source/model_sharing.rst:385
msgid ""
"First you need to install `git-lfs` in the environment used by the "
"notebook:"
msgstr ""

#: ../../source/model_sharing.rst:391
msgid ""
"Then you can use either create a repo directly from `huggingface.co "
"<https://huggingface.co/>`__ , or use the :obj:`transformers-cli` to "
"create it:"
msgstr ""

#: ../../source/model_sharing.rst:400
msgid ""
"Once it's created, you can clone it and configure it (replace username by"
" your username on huggingface.co):"
msgstr ""

#: ../../source/model_sharing.rst:416
msgid ""
"Once you've saved your model inside, and your clone is setup with the "
"right remote URL, you can add it and push it with usual git commands."
msgstr ""

