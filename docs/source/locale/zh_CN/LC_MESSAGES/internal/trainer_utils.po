# SOME DESCRIPTIVE TITLE.
# Copyright (C) 2020, The Hugging Face Team, Licenced under the Apache
# License, Version 2.0
# This file is distributed under the same license as the transformers
# package.
# FIRST AUTHOR <EMAIL@ADDRESS>, 2021.
#
#, fuzzy
msgid ""
msgstr ""
"Project-Id-Version: transformers \n"
"Report-Msgid-Bugs-To: \n"
"POT-Creation-Date: 2021-07-30 16:44+0800\n"
"PO-Revision-Date: YEAR-MO-DA HO:MI+ZONE\n"
"Last-Translator: FULL NAME <EMAIL@ADDRESS>\n"
"Language-Team: LANGUAGE <LL@li.org>\n"
"MIME-Version: 1.0\n"
"Content-Type: text/plain; charset=utf-8\n"
"Content-Transfer-Encoding: 8bit\n"
"Generated-By: Babel 2.8.0\n"

#: ../../source/internal/trainer_utils.rst:14
msgid "Utilities for Trainer"
msgstr ""

#: ../../source/internal/trainer_utils.rst:16
msgid ""
"This page lists all the utility functions used by "
":class:`~transformers.Trainer`."
msgstr ""

#: ../../source/internal/trainer_utils.rst:18
msgid ""
"Most of those are only useful if you are studying the code of the Trainer"
" in the library."
msgstr ""

#: ../../source/internal/trainer_utils.rst:21
msgid "Utilities"
msgstr ""

#: of transformers.EvalPrediction:1
msgid "Evaluation output (always contains labels), to be used to compute metrics."
msgstr ""

#: of transformers.EvalPrediction
#: transformers.debug_utils.DebugUnderflowOverflow transformers.set_seed
#: transformers.torch_distributed_zero_first
#: transformers.trainer_pt_utils.DistributedTensorGatherer
msgid "Parameters"
msgstr ""

#: of transformers.EvalPrediction:3
msgid "Predictions of the model."
msgstr ""

#: of transformers.EvalPrediction:5
msgid "Targets to be matched."
msgstr ""

#: of transformers.IntervalStrategy:1
msgid "An enumeration."
msgstr ""

#: of transformers.set_seed:1
msgid ""
"Helper function for reproducible behavior to set the seed in ``random``, "
"``numpy``, ``torch`` and/or ``tf`` (if installed)."
msgstr ""

#: of transformers.set_seed:4
msgid "The seed to set."
msgstr ""

#: of transformers.torch_distributed_zero_first:1
msgid ""
"Decorator to make all processes in distributed training wait for each "
"local_master to do something."
msgstr ""

#: of transformers.torch_distributed_zero_first:3
msgid "The rank of the local process."
msgstr ""

#: ../../source/internal/trainer_utils.rst:33
msgid "Callbacks internals"
msgstr ""

#: of transformers.trainer_callback.CallbackHandler:1
msgid "Internal class that just calls the list of callbacks in order."
msgstr ""

#: ../../source/internal/trainer_utils.rst:39
#: ../../source/internal/trainer_utils.rst:46
msgid "Distributed Evaluation"
msgstr ""

#: of transformers.trainer_pt_utils.DistributedTensorGatherer:1
msgid ""
"A class responsible for properly gathering tensors (or nested list/tuple "
"of tensors) on the CPU by chunks."
msgstr ""

#: of transformers.trainer_pt_utils.DistributedTensorGatherer:3
msgid ""
"If our dataset has 16 samples with a batch size of 2 on 3 processes and "
"we gather then transfer on CPU at every step, our sampler will generate "
"the following indices:"
msgstr ""

#: of transformers.trainer_pt_utils.DistributedTensorGatherer:6
msgid ":obj:`[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 0, 1]`"
msgstr ""

#: of transformers.trainer_pt_utils.DistributedTensorGatherer:8
msgid ""
"to get something of size a multiple of 3 (so that each process gets the "
"same dataset length). Then process 0, 1 and 2 will be responsible of "
"making predictions for the following samples:"
msgstr ""

#: of transformers.trainer_pt_utils.DistributedTensorGatherer:11
msgid "P0: :obj:`[0, 1, 2, 3, 4, 5]`"
msgstr ""

#: of transformers.trainer_pt_utils.DistributedTensorGatherer:12
msgid "P1: :obj:`[6, 7, 8, 9, 10, 11]`"
msgstr ""

#: of transformers.trainer_pt_utils.DistributedTensorGatherer:13
msgid "P2: :obj:`[12, 13, 14, 15, 0, 1]`"
msgstr ""

#: of transformers.trainer_pt_utils.DistributedTensorGatherer:15
msgid "The first batch treated on each process will be"
msgstr ""

#: of transformers.trainer_pt_utils.DistributedTensorGatherer:17
msgid "P0: :obj:`[0, 1]`"
msgstr ""

#: of transformers.trainer_pt_utils.DistributedTensorGatherer:18
msgid "P1: :obj:`[6, 7]`"
msgstr ""

#: of transformers.trainer_pt_utils.DistributedTensorGatherer:19
msgid "P2: :obj:`[12, 13]`"
msgstr ""

#: of transformers.trainer_pt_utils.DistributedTensorGatherer:21
msgid ""
"So if we gather at the end of the first batch, we will get a tensor "
"(nested list/tuple of tensor) corresponding to the following indices:"
msgstr ""

#: of transformers.trainer_pt_utils.DistributedTensorGatherer:24
msgid ":obj:`[0, 1, 6, 7, 12, 13]`"
msgstr ""

#: of transformers.trainer_pt_utils.DistributedTensorGatherer:26
msgid ""
"If we directly concatenate our results without taking any precautions, "
"the user will then get the predictions for the indices in this order at "
"the end of the prediction loop:"
msgstr ""

#: of transformers.trainer_pt_utils.DistributedTensorGatherer:29
msgid ":obj:`[0, 1, 6, 7, 12, 13, 2, 3, 8, 9, 14, 15, 4, 5, 10, 11, 0, 1]`"
msgstr ""

#: of transformers.trainer_pt_utils.DistributedTensorGatherer:31
msgid ""
"For some reason, that's not going to roll their boat. This class is there"
" to solve that problem."
msgstr ""

#: of transformers.trainer_pt_utils.DistributedTensorGatherer:33
msgid "The number of processes used in the distributed training."
msgstr ""

#: of transformers.trainer_pt_utils.DistributedTensorGatherer:35
msgid "The number of samples in our dataset."
msgstr ""

#: of transformers.trainer_pt_utils.DistributedTensorGatherer:37
msgid ""
"If passed, the class assumes the datasets passed to each process are made"
" to be a multiple of this argument (by adding samples)."
msgstr ""

#: of transformers.trainer_pt_utils.DistributedTensorGatherer:40
msgid ""
"The padding index to use if the arrays don't all have the same sequence "
"length."
msgstr ""

#: of transformers.trainer_pt_utils.DistributedTensorGatherer.add_arrays:1
msgid ""
"Add :obj:`arrays` to the internal storage, Will initialize the storage to"
" the full size at the first arrays passed so that if we're bound to get "
"an OOM, it happens at the beginning."
msgstr ""

#: of transformers.trainer_pt_utils.DistributedTensorGatherer.finalize:1
msgid ""
"Return the properly gathered arrays and truncate to the number of samples"
" (since the sampler added some extras to get each process a dataset of "
"the same length)."
msgstr ""

#: of transformers.HfArgumentParser:1
msgid ""
"This subclass of `argparse.ArgumentParser` uses type hints on dataclasses"
" to generate arguments."
msgstr ""

#: of transformers.HfArgumentParser:3
msgid ""
"The class is designed to play well with the native argparse. In "
"particular, you can add more (non-dataclass backed) arguments to the "
"parser after initialization and you'll get the output back after parsing "
"as an additional namespace. Optional: To create sub argument groups use "
"the `_argument_group_name` attribute in the dataclass."
msgstr ""

#: ../../source/internal/trainer_utils.rst:52
msgid "Debug Utilities"
msgstr ""

#: of transformers.debug_utils.DebugUnderflowOverflow:1
msgid ""
"This debug class helps detect and understand where the model starts "
"getting very large or very small, and more importantly ``nan`` or ``inf``"
" weight and activation elements."
msgstr ""

#: of transformers.debug_utils.DebugUnderflowOverflow:4
msgid "There are 2 working modes:"
msgstr ""

#: of transformers.debug_utils.DebugUnderflowOverflow:6
msgid "Underflow/overflow detection (default)"
msgstr ""

#: of transformers.debug_utils.DebugUnderflowOverflow:7
msgid "Specific batch absolute min/max tracing without detection"
msgstr ""

#: of transformers.debug_utils.DebugUnderflowOverflow:9
msgid "Mode 1: Underflow/overflow detection"
msgstr ""

#: of transformers.debug_utils.DebugUnderflowOverflow:11
msgid ""
"To activate the underflow/overflow detection, initialize the object with "
"the model ::"
msgstr ""

#: of transformers.debug_utils.DebugUnderflowOverflow:15
msgid ""
"then run the training as normal and if ``nan`` or ``inf`` gets detected "
"in at least one of the weight, input or output elements this module will "
"throw an exception and will print ``max_frames_to_save`` frames that lead"
" to this event, each frame reporting"
msgstr ""

#: of transformers.debug_utils.DebugUnderflowOverflow:19
msgid ""
"the fully qualified module name plus the class name whose ``forward`` was"
" run"
msgstr ""

#: of transformers.debug_utils.DebugUnderflowOverflow:20
msgid ""
"the absolute min and max value of all elements for each module weights, "
"and the inputs and output"
msgstr ""

#: of transformers.debug_utils.DebugUnderflowOverflow:22
msgid ""
"For example, here is the header and the last few frames in detection "
"report for ``google/mt5-small`` run in fp16 mixed precision ::"
msgstr ""

#: of transformers.debug_utils.DebugUnderflowOverflow:47
msgid ""
"You can see here, that ``T5DenseGatedGeluDense.forward`` resulted in "
"output activations, whose absolute max value was around 62.7K, which is "
"very close to fp16's top limit of 64K. In the next frame we have "
"``Dropout`` which renormalizes the weights, after it zeroed some of the "
"elements, which pushes the absolute max value to more than 64K, and we "
"get an overlow."
msgstr ""

#: of transformers.debug_utils.DebugUnderflowOverflow:52
msgid ""
"As you can see it's the previous frames that we need to look into when "
"the numbers start going into very large for fp16 numbers."
msgstr ""

#: of transformers.debug_utils.DebugUnderflowOverflow:55
msgid ""
"The tracking is done in a forward hook, which gets invoked immediately "
"after ``forward`` has completed."
msgstr ""

#: of transformers.debug_utils.DebugUnderflowOverflow:57
msgid ""
"By default the last 21 frames are printed. You can change the default to "
"adjust for your needs. For example ::"
msgstr ""

#: of transformers.debug_utils.DebugUnderflowOverflow:61
msgid ""
"To validate that you have set up this debugging feature correctly, and "
"you intend to use it in a training that may take hours to complete, first"
" run it with normal tracing enabled for one of a few batches as explained"
" in the next section."
msgstr ""

#: of transformers.debug_utils.DebugUnderflowOverflow:66
msgid "Mode 2. Specific batch absolute min/max tracing without detection"
msgstr ""

#: of transformers.debug_utils.DebugUnderflowOverflow:68
msgid ""
"The second work mode is per-batch tracing with the underflow/overflow "
"detection feature turned off."
msgstr ""

#: of transformers.debug_utils.DebugUnderflowOverflow:70
msgid ""
"Let's say you want to watch the absolute min and max values for all the "
"ingredients of each ``forward`` call of a given batch, and only do that "
"for batches 1 and 3. Then you instantiate this class as ::"
msgstr ""

#: of transformers.debug_utils.DebugUnderflowOverflow:75
msgid ""
"And now full batches 1 and 3 will be traced using the same format as "
"explained above. Batches are 0-indexed."
msgstr ""

#: of transformers.debug_utils.DebugUnderflowOverflow:77
msgid ""
"This is helpful if you know that the program starts misbehaving after a "
"certain batch number, so you can fast-forward right to that area."
msgstr ""

#: of transformers.debug_utils.DebugUnderflowOverflow:81
msgid "Early stopping:"
msgstr ""

#: of transformers.debug_utils.DebugUnderflowOverflow:83
msgid ""
"You can also specify the batch number after which to stop the training, "
"with ::"
msgstr ""

#: of transformers.debug_utils.DebugUnderflowOverflow:87
msgid ""
"This feature is mainly useful in the tracing mode, but you can use it for"
" any mode."
msgstr ""

#: of transformers.debug_utils.DebugUnderflowOverflow:90
msgid "**Performance**:"
msgstr ""

#: of transformers.debug_utils.DebugUnderflowOverflow:92
msgid ""
"As this module measures absolute ``min``/``max`` of each weight of the "
"model on every forward it'll slow the training down. Therefore remember "
"to turn it off once the debugging needs have been met."
msgstr ""

#: of transformers.debug_utils.DebugUnderflowOverflow:95
msgid "The model to debug."
msgstr ""

#: of transformers.debug_utils.DebugUnderflowOverflow:97
msgid "How many frames back to record"
msgstr ""

#: of transformers.debug_utils.DebugUnderflowOverflow:99
msgid "Which batch numbers to trace (turns detection off)"
msgstr ""

#: of transformers.debug_utils.DebugUnderflowOverflow:101
msgid "Whether to abort after a certain batch number has finished"
msgstr ""

