# SOME DESCRIPTIVE TITLE.
# Copyright (C) 2020, The Hugging Face Team, Licenced under the Apache
# License, Version 2.0
# This file is distributed under the same license as the transformers
# package.
# FIRST AUTHOR <EMAIL@ADDRESS>, 2021.
#
#, fuzzy
msgid ""
msgstr ""
"Project-Id-Version: transformers \n"
"Report-Msgid-Bugs-To: \n"
"POT-Creation-Date: 2021-07-30 16:44+0800\n"
"PO-Revision-Date: YEAR-MO-DA HO:MI+ZONE\n"
"Last-Translator: FULL NAME <EMAIL@ADDRESS>\n"
"Language-Team: LANGUAGE <LL@li.org>\n"
"MIME-Version: 1.0\n"
"Content-Type: text/plain; charset=utf-8\n"
"Content-Transfer-Encoding: 8bit\n"
"Generated-By: Babel 2.8.0\n"

#: ../../source/model_doc/camembert.rst:14
msgid "CamemBERT"
msgstr ""

#: ../../source/model_doc/camembert.rst:17
msgid "Overview"
msgstr ""

#: ../../source/model_doc/camembert.rst:19
msgid ""
"The CamemBERT model was proposed in `CamemBERT: a Tasty French Language "
"Model <https://arxiv.org/abs/1911.03894>`__ by Louis Martin, Benjamin "
"Muller, Pedro Javier Ortiz Suárez, Yoann Dupont, Laurent Romary, Éric "
"Villemonte de la Clergerie, Djamé Seddah, and Benoît Sagot. It is based "
"on Facebook's RoBERTa model released in 2019. It is a model trained on "
"138GB of French text."
msgstr ""

#: ../../source/model_doc/camembert.rst:24
msgid "The abstract from the paper is the following:"
msgstr ""

#: ../../source/model_doc/camembert.rst:26
msgid ""
"*Pretrained language models are now ubiquitous in Natural Language "
"Processing. Despite their success, most available models have either been"
" trained on English data or on the concatenation of data in multiple "
"languages. This makes practical use of such models --in all languages "
"except English-- very limited. Aiming to address this issue for French, "
"we release CamemBERT, a French version of the Bi-directional Encoders for"
" Transformers (BERT). We measure the performance of CamemBERT compared to"
" multilingual models in multiple downstream tasks, namely part-of-speech "
"tagging, dependency parsing, named-entity recognition, and natural "
"language inference. CamemBERT improves the state of the art for most of "
"the tasks considered. We release the pretrained model for CamemBERT "
"hoping to foster research and downstream applications for French NLP.*"
msgstr ""

#: ../../source/model_doc/camembert.rst:35
msgid "Tips:"
msgstr ""

#: ../../source/model_doc/camembert.rst:37
msgid ""
"This implementation is the same as RoBERTa. Refer to the "
":doc:`documentation of RoBERTa <roberta>` for usage examples as well as "
"the information relative to the inputs and outputs."
msgstr ""

#: ../../source/model_doc/camembert.rst:40
msgid ""
"This model was contributed by `camembert "
"<https://huggingface.co/camembert>`__. The original code can be found "
"`here <https://camembert-model.fr/>`__."
msgstr ""

#: ../../source/model_doc/camembert.rst:44
msgid "CamembertConfig"
msgstr ""

#: of transformers.CamembertConfig:1
msgid ""
"This class overrides :class:`~transformers.RobertaConfig`. Please check "
"the superclass for the appropriate documentation alongside usage "
"examples."
msgstr ""

#: ../../source/model_doc/camembert.rst:51
msgid "CamembertTokenizer"
msgstr ""

#: of transformers.CamembertTokenizer:1
msgid ""
"Adapted from :class:`~transformers.RobertaTokenizer` and "
":class:`~transformers.XLNetTokenizer`. Construct a CamemBERT tokenizer. "
"Based on `SentencePiece <https://github.com/google/sentencepiece>`__."
msgstr ""

#: of transformers.CamembertTokenizer:4
msgid ""
"This tokenizer inherits from :class:`~transformers.PreTrainedTokenizer` "
"which contains most of the main methods. Users should refer to this "
"superclass for more information regarding those methods."
msgstr ""

#: of transformers.CamembertForCausalLM transformers.CamembertForMaskedLM
#: transformers.CamembertForMultipleChoice
#: transformers.CamembertForQuestionAnswering
#: transformers.CamembertForSequenceClassification
#: transformers.CamembertForTokenClassification transformers.CamembertModel
#: transformers.CamembertTokenizer
#: transformers.CamembertTokenizer.build_inputs_with_special_tokens
#: transformers.CamembertTokenizer.create_token_type_ids_from_sequences
#: transformers.CamembertTokenizer.get_special_tokens_mask
#: transformers.CamembertTokenizer.save_vocabulary
#: transformers.CamembertTokenizerFast
#: transformers.CamembertTokenizerFast.build_inputs_with_special_tokens
#: transformers.CamembertTokenizerFast.create_token_type_ids_from_sequences
#: transformers.CamembertTokenizerFast.save_vocabulary
#: transformers.TFCamembertForMaskedLM
#: transformers.TFCamembertForMultipleChoice
#: transformers.TFCamembertForQuestionAnswering
#: transformers.TFCamembertForSequenceClassification
#: transformers.TFCamembertForTokenClassification transformers.TFCamembertModel
msgid "Parameters"
msgstr ""

#: of transformers.CamembertTokenizer:7 transformers.CamembertTokenizerFast:8
msgid ""
"`SentencePiece <https://github.com/google/sentencepiece>`__ file "
"(generally has a `.spm` extension) that contains the vocabulary necessary"
" to instantiate a tokenizer."
msgstr ""

#: of transformers.CamembertTokenizer:10 transformers.CamembertTokenizerFast:11
msgid ""
"The beginning of sequence token that was used during pretraining. Can be "
"used a sequence classifier token.  .. note::      When building a "
"sequence using special tokens, this is not the token that is used for the"
" beginning of     sequence. The token used is the :obj:`cls_token`."
msgstr ""

#: of transformers.CamembertTokenizer:10 transformers.CamembertTokenizerFast:11
msgid ""
"The beginning of sequence token that was used during pretraining. Can be "
"used a sequence classifier token."
msgstr ""

#: of transformers.CamembertTokenizer:14 transformers.CamembertTokenizerFast:15
msgid ""
"When building a sequence using special tokens, this is not the token that"
" is used for the beginning of sequence. The token used is the "
":obj:`cls_token`."
msgstr ""

#: of transformers.CamembertTokenizer:17 transformers.CamembertTokenizerFast:18
msgid ""
"The end of sequence token.  .. note::      When building a sequence using"
" special tokens, this is not the token that is used for the end of     "
"sequence. The token used is the :obj:`sep_token`."
msgstr ""

#: of transformers.CamembertTokenizer:17 transformers.CamembertTokenizerFast:18
msgid "The end of sequence token."
msgstr ""

#: of transformers.CamembertTokenizer:21 transformers.CamembertTokenizerFast:22
msgid ""
"When building a sequence using special tokens, this is not the token that"
" is used for the end of sequence. The token used is the :obj:`sep_token`."
msgstr ""

#: of transformers.CamembertTokenizer:24 transformers.CamembertTokenizerFast:25
msgid ""
"The separator token, which is used when building a sequence from multiple"
" sequences, e.g. two sequences for sequence classification or for a text "
"and a question for question answering. It is also used as the last token "
"of a sequence built with special tokens."
msgstr ""

#: of transformers.CamembertTokenizer:28 transformers.CamembertTokenizerFast:29
msgid ""
"The classifier token which is used when doing sequence classification "
"(classification of the whole sequence instead of per-token "
"classification). It is the first token of the sequence when built with "
"special tokens."
msgstr ""

#: of transformers.CamembertTokenizer:31 transformers.CamembertTokenizerFast:32
msgid ""
"The unknown token. A token that is not in the vocabulary cannot be "
"converted to an ID and is set to be this token instead."
msgstr ""

#: of transformers.CamembertTokenizer:34 transformers.CamembertTokenizerFast:35
msgid ""
"The token used for padding, for example when batching sequences of "
"different lengths."
msgstr ""

#: of transformers.CamembertTokenizer:36 transformers.CamembertTokenizerFast:37
msgid ""
"The token used for masking values. This is the token used when training "
"this model with masked language modeling. This is the token which the "
"model will try to predict."
msgstr ""

#: of transformers.CamembertTokenizer:39 transformers.CamembertTokenizerFast:40
msgid "Additional special tokens used by the tokenizer."
msgstr ""

#: of transformers.CamembertTokenizer:41
msgid ""
"Will be passed to the ``SentencePieceProcessor.__init__()`` method. The "
"`Python wrapper for SentencePiece "
"<https://github.com/google/sentencepiece/tree/master/python>`__ can be "
"used, among other things, to set:  - ``enable_sampling``: Enable subword "
"regularization. - ``nbest_size``: Sampling parameters for unigram. "
"Invalid for BPE-Dropout.    - ``nbest_size = {0,1}``: No sampling is "
"performed.   - ``nbest_size > 1``: samples from the nbest_size results."
"   - ``nbest_size < 0``: assuming that nbest_size is infinite and samples"
" from the all hypothesis (lattice)     using forward-filtering-and-"
"backward-sampling algorithm.  - ``alpha``: Smoothing parameter for "
"unigram sampling, and dropout probability of merge operations for   BPE-"
"dropout."
msgstr ""

#: of transformers.CamembertTokenizer:41
msgid ""
"Will be passed to the ``SentencePieceProcessor.__init__()`` method. The "
"`Python wrapper for SentencePiece "
"<https://github.com/google/sentencepiece/tree/master/python>`__ can be "
"used, among other things, to set:"
msgstr ""

#: of transformers.CamembertTokenizer:44
msgid "``enable_sampling``: Enable subword regularization."
msgstr ""

#: of transformers.CamembertTokenizer:45
msgid "``nbest_size``: Sampling parameters for unigram. Invalid for BPE-Dropout."
msgstr ""

#: of transformers.CamembertTokenizer:47
msgid "``nbest_size = {0,1}``: No sampling is performed."
msgstr ""

#: of transformers.CamembertTokenizer:48
msgid "``nbest_size > 1``: samples from the nbest_size results."
msgstr ""

#: of transformers.CamembertTokenizer:49
msgid ""
"``nbest_size < 0``: assuming that nbest_size is infinite and samples from"
" the all hypothesis (lattice) using forward-filtering-and-backward-"
"sampling algorithm."
msgstr ""

#: of transformers.CamembertTokenizer:52
msgid ""
"``alpha``: Smoothing parameter for unigram sampling, and dropout "
"probability of merge operations for BPE-dropout."
msgstr ""

#: of transformers.CamembertTokenizer:58
msgid ""
"The `SentencePiece` processor that is used for every conversion (string, "
"tokens and IDs)."
msgstr ""

#: of transformers.CamembertTokenizer
msgid "type"
msgstr ""

#: of transformers.CamembertTokenizer:60
msgid ":obj:`SentencePieceProcessor`"
msgstr ""

#: of transformers.CamembertTokenizer.build_inputs_with_special_tokens:1
#: transformers.CamembertTokenizerFast.build_inputs_with_special_tokens:1
msgid ""
"Build model inputs from a sequence or a pair of sequence for sequence "
"classification tasks by concatenating and adding special tokens. An "
"CamemBERT sequence has the following format:"
msgstr ""

#: of transformers.CamembertTokenizer.build_inputs_with_special_tokens:4
#: transformers.CamembertTokenizerFast.build_inputs_with_special_tokens:4
msgid "single sequence: ``<s> X </s>``"
msgstr ""

#: of transformers.CamembertTokenizer.build_inputs_with_special_tokens:5
#: transformers.CamembertTokenizerFast.build_inputs_with_special_tokens:5
msgid "pair of sequences: ``<s> A </s></s> B </s>``"
msgstr ""

#: of transformers.CamembertTokenizer.build_inputs_with_special_tokens:7
#: transformers.CamembertTokenizerFast.build_inputs_with_special_tokens:7
msgid "List of IDs to which the special tokens will be added."
msgstr ""

#: of transformers.CamembertTokenizer.build_inputs_with_special_tokens:9
#: transformers.CamembertTokenizer.create_token_type_ids_from_sequences:6
#: transformers.CamembertTokenizer.get_special_tokens_mask:6
#: transformers.CamembertTokenizerFast.build_inputs_with_special_tokens:9
#: transformers.CamembertTokenizerFast.create_token_type_ids_from_sequences:6
msgid "Optional second list of IDs for sequence pairs."
msgstr ""

#: of transformers.CamembertTokenizer.build_inputs_with_special_tokens
#: transformers.CamembertTokenizer.create_token_type_ids_from_sequences
#: transformers.CamembertTokenizer.get_special_tokens_mask
#: transformers.CamembertTokenizer.save_vocabulary
#: transformers.CamembertTokenizerFast.build_inputs_with_special_tokens
#: transformers.CamembertTokenizerFast.create_token_type_ids_from_sequences
#: transformers.CamembertTokenizerFast.save_vocabulary
msgid "Returns"
msgstr ""

#: of transformers.CamembertTokenizer.build_inputs_with_special_tokens:12
#: transformers.CamembertTokenizerFast.build_inputs_with_special_tokens:12
msgid ""
"List of `input IDs <../glossary.html#input-ids>`__ with the appropriate "
"special tokens."
msgstr ""

#: of transformers.CamembertTokenizer.build_inputs_with_special_tokens
#: transformers.CamembertTokenizer.create_token_type_ids_from_sequences
#: transformers.CamembertTokenizer.get_special_tokens_mask
#: transformers.CamembertTokenizer.save_vocabulary
#: transformers.CamembertTokenizerFast.build_inputs_with_special_tokens
#: transformers.CamembertTokenizerFast.create_token_type_ids_from_sequences
#: transformers.CamembertTokenizerFast.save_vocabulary
msgid "Return type"
msgstr ""

#: of transformers.CamembertTokenizer.build_inputs_with_special_tokens:13
#: transformers.CamembertTokenizer.create_token_type_ids_from_sequences:10
#: transformers.CamembertTokenizer.get_special_tokens_mask:12
#: transformers.CamembertTokenizerFast.build_inputs_with_special_tokens:13
#: transformers.CamembertTokenizerFast.create_token_type_ids_from_sequences:10
msgid ":obj:`List[int]`"
msgstr ""

#: of transformers.CamembertTokenizer.create_token_type_ids_from_sequences:1
#: transformers.CamembertTokenizerFast.create_token_type_ids_from_sequences:1
msgid ""
"Create a mask from the two sequences passed to be used in a sequence-pair"
" classification task. CamemBERT, like RoBERTa, does not make use of token"
" type ids, therefore a list of zeros is returned."
msgstr ""

#: of transformers.CamembertTokenizer.create_token_type_ids_from_sequences:4
#: transformers.CamembertTokenizer.get_special_tokens_mask:4
#: transformers.CamembertTokenizerFast.create_token_type_ids_from_sequences:4
msgid "List of IDs."
msgstr ""

#: of transformers.CamembertTokenizer.create_token_type_ids_from_sequences:9
#: transformers.CamembertTokenizerFast.create_token_type_ids_from_sequences:9
msgid "List of zeros."
msgstr ""

#: of transformers.CamembertTokenizer.get_special_tokens_mask:1
msgid ""
"Retrieve sequence ids from a token list that has no special tokens added."
" This method is called when adding special tokens using the tokenizer "
"``prepare_for_model`` method."
msgstr ""

#: of transformers.CamembertTokenizer.get_special_tokens_mask:8
msgid ""
"Whether or not the token list is already formatted with special tokens "
"for the model."
msgstr ""

#: of transformers.CamembertTokenizer.get_special_tokens_mask:11
msgid ""
"A list of integers in the range [0, 1]: 1 for a special token, 0 for a "
"sequence token."
msgstr ""

#: of transformers.CamembertTokenizer.save_vocabulary:1
#: transformers.CamembertTokenizerFast.save_vocabulary:1
msgid "Save only the vocabulary of the tokenizer (vocabulary + added tokens)."
msgstr ""

#: of transformers.CamembertTokenizer.save_vocabulary:3
#: transformers.CamembertTokenizerFast.save_vocabulary:3
msgid ""
"This method won't save the configuration and special token mappings of "
"the tokenizer. Use "
":meth:`~transformers.PreTrainedTokenizerFast._save_pretrained` to save "
"the whole state of the tokenizer."
msgstr ""

#: of transformers.CamembertTokenizer.save_vocabulary:6
#: transformers.CamembertTokenizerFast.save_vocabulary:6
msgid "The directory in which to save the vocabulary."
msgstr ""

#: of transformers.CamembertTokenizer.save_vocabulary:8
#: transformers.CamembertTokenizerFast.save_vocabulary:8
msgid "An optional prefix to add to the named of the saved files."
msgstr ""

#: of transformers.CamembertTokenizer.save_vocabulary:11
#: transformers.CamembertTokenizerFast.save_vocabulary:11
msgid "Paths to the files saved."
msgstr ""

#: of transformers.CamembertTokenizer.save_vocabulary:12
#: transformers.CamembertTokenizerFast.save_vocabulary:12
msgid ":obj:`Tuple(str)`"
msgstr ""

#: ../../source/model_doc/camembert.rst:59
msgid "CamembertTokenizerFast"
msgstr ""

#: of transformers.CamembertTokenizerFast:1
msgid ""
"Construct a \"fast\" CamemBERT tokenizer (backed by HuggingFace's "
"`tokenizers` library). Adapted from "
":class:`~transformers.RobertaTokenizer` and "
":class:`~transformers.XLNetTokenizer`. Based on `BPE "
"<https://huggingface.co/docs/tokenizers/python/latest/components.html?highlight=BPE#models>`__."
msgstr ""

#: of transformers.CamembertTokenizerFast:5
msgid ""
"This tokenizer inherits from "
":class:`~transformers.PreTrainedTokenizerFast` which contains most of the"
" main methods. Users should refer to this superclass for more information"
" regarding those methods."
msgstr ""

#: ../../source/model_doc/camembert.rst:66
msgid "CamembertModel"
msgstr ""

#: of transformers.CamembertModel:1 transformers.TFCamembertModel:1
msgid ""
"The bare CamemBERT Model transformer outputting raw hidden-states without"
" any specific head on top."
msgstr ""

#: of transformers.CamembertForCausalLM:3 transformers.CamembertForMaskedLM:3
#: transformers.CamembertForMultipleChoice:5
#: transformers.CamembertForQuestionAnswering:5
#: transformers.CamembertForSequenceClassification:5
#: transformers.CamembertForTokenClassification:5 transformers.CamembertModel:3
msgid ""
"This model inherits from :class:`~transformers.PreTrainedModel`. Check "
"the superclass documentation for the generic methods the library "
"implements for all its model (such as downloading or saving, resizing the"
" input embeddings, pruning heads etc.)"
msgstr ""

#: of transformers.CamembertForCausalLM:7 transformers.CamembertForMaskedLM:7
#: transformers.CamembertForMultipleChoice:9
#: transformers.CamembertForQuestionAnswering:9
#: transformers.CamembertForSequenceClassification:9
#: transformers.CamembertForTokenClassification:9 transformers.CamembertModel:7
msgid ""
"This model is also a PyTorch `torch.nn.Module "
"<https://pytorch.org/docs/stable/nn.html#torch.nn.Module>`__ subclass. "
"Use it as a regular PyTorch Module and refer to the PyTorch documentation"
" for all matter related to general usage and behavior."
msgstr ""

#: of transformers.CamembertForCausalLM:11 transformers.CamembertForMaskedLM:11
#: transformers.CamembertForMultipleChoice:13
#: transformers.CamembertForQuestionAnswering:13
#: transformers.CamembertForSequenceClassification:13
#: transformers.CamembertForTokenClassification:13
#: transformers.CamembertModel:11 transformers.TFCamembertForMaskedLM:30
#: transformers.TFCamembertForMultipleChoice:32
#: transformers.TFCamembertForQuestionAnswering:32
#: transformers.TFCamembertForSequenceClassification:32
#: transformers.TFCamembertForTokenClassification:32
#: transformers.TFCamembertModel:30
msgid ""
"Model configuration class with all the parameters of the model. "
"Initializing with a config file does not load the weights associated with"
" the model, only the configuration. Check out the "
":meth:`~transformers.PreTrainedModel.from_pretrained` method to load the "
"model weights."
msgstr ""

#: of transformers.CamembertModel:17
msgid ""
"This class overrides :class:`~transformers.RobertaModel`. Please check "
"the superclass for the appropriate documentation alongside usage "
"examples."
msgstr ""

#: ../../source/model_doc/camembert.rst:73
msgid "CamembertForCausalLM"
msgstr ""

#: of transformers.CamembertForCausalLM:1
msgid ""
"CamemBERT Model with a `language modeling` head on top for CLM fine-"
"tuning."
msgstr ""

#: of transformers.CamembertForCausalLM:17
msgid ""
"This class overrides :class:`~transformers.RobertaForCausalLM`. Please "
"check the superclass for the appropriate documentation alongside usage "
"examples."
msgstr ""

#: ../../source/model_doc/camembert.rst:80
msgid "CamembertForMaskedLM"
msgstr ""

#: of transformers.CamembertForMaskedLM:1 transformers.TFCamembertForMaskedLM:1
msgid "CamemBERT Model with a `language modeling` head on top."
msgstr ""

#: of transformers.CamembertForMaskedLM:17
msgid ""
"This class overrides :class:`~transformers.RobertaForMaskedLM`. Please "
"check the superclass for the appropriate documentation alongside usage "
"examples."
msgstr ""

#: ../../source/model_doc/camembert.rst:87
msgid "CamembertForSequenceClassification"
msgstr ""

#: of transformers.CamembertForSequenceClassification:1
#: transformers.TFCamembertForSequenceClassification:1
msgid ""
"CamemBERT Model transformer with a sequence classification/regression "
"head on top (a linear layer on top of the pooled output) e.g. for GLUE "
"tasks."
msgstr ""

#: of transformers.CamembertForSequenceClassification:19
msgid ""
"This class overrides "
":class:`~transformers.RobertaForSequenceClassification`. Please check the"
" superclass for the appropriate documentation alongside usage examples."
msgstr ""

#: ../../source/model_doc/camembert.rst:94
msgid "CamembertForMultipleChoice"
msgstr ""

#: of transformers.CamembertForMultipleChoice:1
#: transformers.TFCamembertForMultipleChoice:1
msgid ""
"CamemBERT Model with a multiple choice classification head on top (a "
"linear layer on top of the pooled output and a softmax) e.g. for "
"RocStories/SWAG tasks."
msgstr ""

#: of transformers.CamembertForMultipleChoice:19
msgid ""
"This class overrides :class:`~transformers.RobertaForMultipleChoice`. "
"Please check the superclass for the appropriate documentation alongside "
"usage examples."
msgstr ""

#: ../../source/model_doc/camembert.rst:101
msgid "CamembertForTokenClassification"
msgstr ""

#: of transformers.CamembertForTokenClassification:1
#: transformers.TFCamembertForTokenClassification:1
msgid ""
"CamemBERT Model with a token classification head on top (a linear layer "
"on top of the hidden-states output) e.g. for Named-Entity-Recognition "
"(NER) tasks."
msgstr ""

#: of transformers.CamembertForTokenClassification:19
msgid ""
"This class overrides "
":class:`~transformers.RobertaForTokenClassification`. Please check the "
"superclass for the appropriate documentation alongside usage examples."
msgstr ""

#: ../../source/model_doc/camembert.rst:108
msgid "CamembertForQuestionAnswering"
msgstr ""

#: of transformers.CamembertForQuestionAnswering:1
msgid ""
"CamemBERT Model with a span classification head on top for extractive "
"question-answering tasks like SQuAD (a linear layers on top of the "
"hidden-states output to compute `span start logits` and `span end logits`"
msgstr ""

#: of transformers.CamembertForQuestionAnswering:19
msgid ""
"This class overrides :class:`~transformers.RobertaForQuestionAnswering`. "
"Please check the superclass for the appropriate documentation alongside "
"usage examples."
msgstr ""

#: ../../source/model_doc/camembert.rst:115
msgid "TFCamembertModel"
msgstr ""

#: of transformers.TFCamembertForMaskedLM:3
#: transformers.TFCamembertForMultipleChoice:5
#: transformers.TFCamembertForQuestionAnswering:5
#: transformers.TFCamembertForSequenceClassification:5
#: transformers.TFCamembertForTokenClassification:5
#: transformers.TFCamembertModel:3
msgid ""
"This model inherits from :class:`~transformers.TFPreTrainedModel`. Check "
"the superclass documentation for the generic methods the library "
"implements for all its model (such as downloading or saving, resizing the"
" input embeddings, pruning heads etc.)"
msgstr ""

#: of transformers.TFCamembertForMaskedLM:7
#: transformers.TFCamembertForMultipleChoice:9
#: transformers.TFCamembertForQuestionAnswering:9
#: transformers.TFCamembertForSequenceClassification:9
#: transformers.TFCamembertForTokenClassification:9
#: transformers.TFCamembertModel:7
msgid ""
"This model is also a `tf.keras.Model "
"<https://www.tensorflow.org/api_docs/python/tf/keras/Model>`__ subclass. "
"Use it as a regular TF 2.0 Keras Model and refer to the TF 2.0 "
"documentation for all matter related to general usage and behavior."
msgstr ""

#: of transformers.TFCamembertForMaskedLM:13
#: transformers.TFCamembertForMultipleChoice:15
#: transformers.TFCamembertForQuestionAnswering:15
#: transformers.TFCamembertForSequenceClassification:15
#: transformers.TFCamembertForTokenClassification:15
#: transformers.TFCamembertModel:13
msgid "TF 2.0 models accepts two formats as inputs:"
msgstr ""

#: of transformers.TFCamembertForMaskedLM:15
#: transformers.TFCamembertForMultipleChoice:17
#: transformers.TFCamembertForQuestionAnswering:17
#: transformers.TFCamembertForSequenceClassification:17
#: transformers.TFCamembertForTokenClassification:17
#: transformers.TFCamembertModel:15
msgid "having all inputs as keyword arguments (like PyTorch models), or"
msgstr ""

#: of transformers.TFCamembertForMaskedLM:16
#: transformers.TFCamembertForMultipleChoice:18
#: transformers.TFCamembertForQuestionAnswering:18
#: transformers.TFCamembertForSequenceClassification:18
#: transformers.TFCamembertForTokenClassification:18
#: transformers.TFCamembertModel:16
msgid ""
"having all inputs as a list, tuple or dict in the first positional "
"arguments."
msgstr ""

#: of transformers.TFCamembertForMaskedLM:18
#: transformers.TFCamembertForMultipleChoice:20
#: transformers.TFCamembertForQuestionAnswering:20
#: transformers.TFCamembertForSequenceClassification:20
#: transformers.TFCamembertForTokenClassification:20
#: transformers.TFCamembertModel:18
msgid ""
"This second option is useful when using :meth:`tf.keras.Model.fit` method"
" which currently requires having all the tensors in the first argument of"
" the model call function: :obj:`model(inputs)`."
msgstr ""

#: of transformers.TFCamembertForMaskedLM:21
#: transformers.TFCamembertForMultipleChoice:23
#: transformers.TFCamembertForQuestionAnswering:23
#: transformers.TFCamembertForSequenceClassification:23
#: transformers.TFCamembertForTokenClassification:23
#: transformers.TFCamembertModel:21
msgid ""
"If you choose this second option, there are three possibilities you can "
"use to gather all the input Tensors in the first positional argument :"
msgstr ""

#: of transformers.TFCamembertForMaskedLM:24
#: transformers.TFCamembertForMultipleChoice:26
#: transformers.TFCamembertForQuestionAnswering:26
#: transformers.TFCamembertForSequenceClassification:26
#: transformers.TFCamembertForTokenClassification:26
#: transformers.TFCamembertModel:24
msgid ""
"a single Tensor with :obj:`input_ids` only and nothing else: "
":obj:`model(inputs_ids)`"
msgstr ""

#: of transformers.TFCamembertForMaskedLM:25
#: transformers.TFCamembertForMultipleChoice:27
#: transformers.TFCamembertForQuestionAnswering:27
#: transformers.TFCamembertForSequenceClassification:27
#: transformers.TFCamembertForTokenClassification:27
#: transformers.TFCamembertModel:25
msgid ""
"a list of varying length with one or several input Tensors IN THE ORDER "
"given in the docstring: :obj:`model([input_ids, attention_mask])` or "
":obj:`model([input_ids, attention_mask, token_type_ids])`"
msgstr ""

#: of transformers.TFCamembertForMaskedLM:27
#: transformers.TFCamembertForMultipleChoice:29
#: transformers.TFCamembertForQuestionAnswering:29
#: transformers.TFCamembertForSequenceClassification:29
#: transformers.TFCamembertForTokenClassification:29
#: transformers.TFCamembertModel:27
msgid ""
"a dictionary with one or several input Tensors associated to the input "
"names given in the docstring: :obj:`model({\"input_ids\": input_ids, "
"\"token_type_ids\": token_type_ids})`"
msgstr ""

#: of transformers.TFCamembertModel:36
msgid ""
"This class overrides :class:`~transformers.TFRobertaModel`. Please check "
"the superclass for the appropriate documentation alongside usage "
"examples."
msgstr ""

#: ../../source/model_doc/camembert.rst:122
msgid "TFCamembertForMaskedLM"
msgstr ""

#: of transformers.TFCamembertForMaskedLM:36
msgid ""
"This class overrides :class:`~transformers.TFRobertaForMaskedLM`. Please "
"check the superclass for the appropriate documentation alongside usage "
"examples."
msgstr ""

#: ../../source/model_doc/camembert.rst:129
msgid "TFCamembertForSequenceClassification"
msgstr ""

#: of transformers.TFCamembertForSequenceClassification:38
msgid ""
"This class overrides "
":class:`~transformers.TFRobertaForSequenceClassification`. Please check "
"the superclass for the appropriate documentation alongside usage "
"examples."
msgstr ""

#: ../../source/model_doc/camembert.rst:136
msgid "TFCamembertForMultipleChoice"
msgstr ""

#: of transformers.TFCamembertForMultipleChoice:38
msgid ""
"This class overrides :class:`~transformers.TFRobertaForMultipleChoice`. "
"Please check the superclass for the appropriate documentation alongside "
"usage examples."
msgstr ""

#: ../../source/model_doc/camembert.rst:143
msgid "TFCamembertForTokenClassification"
msgstr ""

#: of transformers.TFCamembertForTokenClassification:38
msgid ""
"This class overrides "
":class:`~transformers.TFRobertaForTokenClassification`. Please check the "
"superclass for the appropriate documentation alongside usage examples."
msgstr ""

#: ../../source/model_doc/camembert.rst:150
msgid "TFCamembertForQuestionAnswering"
msgstr ""

#: of transformers.TFCamembertForQuestionAnswering:1
msgid ""
"CamemBERT Model with a span classification head on top for extractive "
"question-answering tasks like SQuAD (a linear layers on top of the "
"hidden-states output to compute `span start logits` and `span end "
"logits`)."
msgstr ""

#: of transformers.TFCamembertForQuestionAnswering:38
msgid ""
"This class overrides "
":class:`~transformers.TFRobertaForQuestionAnswering`. Please check the "
"superclass for the appropriate documentation alongside usage examples."
msgstr ""

