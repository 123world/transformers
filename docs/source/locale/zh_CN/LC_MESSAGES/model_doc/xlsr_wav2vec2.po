# SOME DESCRIPTIVE TITLE.
# Copyright (C) 2020, The Hugging Face Team, Licenced under the Apache
# License, Version 2.0
# This file is distributed under the same license as the transformers
# package.
# FIRST AUTHOR <EMAIL@ADDRESS>, 2021.
#
#, fuzzy
msgid ""
msgstr ""
"Project-Id-Version: transformers \n"
"Report-Msgid-Bugs-To: \n"
"POT-Creation-Date: 2021-07-30 16:44+0800\n"
"PO-Revision-Date: YEAR-MO-DA HO:MI+ZONE\n"
"Last-Translator: FULL NAME <EMAIL@ADDRESS>\n"
"Language-Team: LANGUAGE <LL@li.org>\n"
"MIME-Version: 1.0\n"
"Content-Type: text/plain; charset=utf-8\n"
"Content-Transfer-Encoding: 8bit\n"
"Generated-By: Babel 2.8.0\n"

#: ../../source/model_doc/xlsr_wav2vec2.rst:14
msgid "XLSR-Wav2Vec2"
msgstr ""

#: ../../source/model_doc/xlsr_wav2vec2.rst:17
msgid "Overview"
msgstr ""

#: ../../source/model_doc/xlsr_wav2vec2.rst:19
msgid ""
"The XLSR-Wav2Vec2 model was proposed in `Unsupervised Cross-Lingual "
"Representation Learning For Speech Recognition "
"<https://arxiv.org/abs/2006.13979>`__ by Alexis Conneau, Alexei Baevski, "
"Ronan Collobert, Abdelrahman Mohamed, Michael Auli."
msgstr ""

#: ../../source/model_doc/xlsr_wav2vec2.rst:23
msgid "The abstract from the paper is the following:"
msgstr ""

#: ../../source/model_doc/xlsr_wav2vec2.rst:25
#, python-format
msgid ""
"*This paper presents XLSR which learns cross-lingual speech "
"representations by pretraining a single model from the raw waveform of "
"speech in multiple languages. We build on wav2vec 2.0 which is trained by"
" solving a contrastive task over masked latent speech representations and"
" jointly learns a quantization of the latents shared across languages. "
"The resulting model is fine-tuned on labeled data and experiments show "
"that cross-lingual pretraining significantly outperforms monolingual "
"pretraining. On the CommonVoice benchmark, XLSR shows a relative phoneme "
"error rate reduction of 72% compared to the best known results. On BABEL,"
" our approach improves word error rate by 16% relative compared to a "
"comparable system. Our approach enables a single multilingual speech "
"recognition model which is competitive to strong individual models. "
"Analysis shows that the latent discrete speech representations are shared"
" across languages with increased sharing for related languages. We hope "
"to catalyze research in low-resource speech understanding by releasing "
"XLSR-53, a large model pretrained in 53 languages.*"
msgstr ""

#: ../../source/model_doc/xlsr_wav2vec2.rst:36
msgid "Tips:"
msgstr ""

#: ../../source/model_doc/xlsr_wav2vec2.rst:38
msgid ""
"XLSR-Wav2Vec2 is a speech model that accepts a float array corresponding "
"to the raw waveform of the speech signal."
msgstr ""

#: ../../source/model_doc/xlsr_wav2vec2.rst:39
msgid ""
"XLSR-Wav2Vec2 model was trained using connectionist temporal "
"classification (CTC) so the model output has to be decoded using "
":class:`~transformers.Wav2Vec2CTCTokenizer`."
msgstr ""

#: ../../source/model_doc/xlsr_wav2vec2.rst:42
msgid ""
"XLSR-Wav2Vec2's architecture is based on the Wav2Vec2 model, so one can "
"refer to :doc:`Wav2Vec2's documentation page <wav2vec2>`."
msgstr ""

#: ../../source/model_doc/xlsr_wav2vec2.rst:45
msgid ""
"The original code can be found `here "
"<https://github.com/pytorch/fairseq/tree/master/fairseq/models/wav2vec>`__."
msgstr ""

