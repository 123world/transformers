# SOME DESCRIPTIVE TITLE.
# Copyright (C) 2020, The Hugging Face Team, Licenced under the Apache
# License, Version 2.0
# This file is distributed under the same license as the transformers
# package.
# FIRST AUTHOR <EMAIL@ADDRESS>, 2021.
#
#, fuzzy
msgid ""
msgstr ""
"Project-Id-Version: transformers \n"
"Report-Msgid-Bugs-To: \n"
"POT-Creation-Date: 2021-07-30 16:44+0800\n"
"PO-Revision-Date: YEAR-MO-DA HO:MI+ZONE\n"
"Last-Translator: FULL NAME <EMAIL@ADDRESS>\n"
"Language-Team: LANGUAGE <LL@li.org>\n"
"MIME-Version: 1.0\n"
"Content-Type: text/plain; charset=utf-8\n"
"Content-Transfer-Encoding: 8bit\n"
"Generated-By: Babel 2.8.0\n"

#: ../../source/converting_tensorflow_models.rst:14
msgid "Converting Tensorflow Checkpoints"
msgstr ""

#: ../../source/converting_tensorflow_models.rst:16
msgid ""
"A command-line interface is provided to convert original Bert/GPT/GPT-2"
"/Transformer-XL/XLNet/XLM checkpoints in models than be loaded using the "
"``from_pretrained`` methods of the library."
msgstr ""

#: ../../source/converting_tensorflow_models.rst:20
msgid ""
"Since 2.3.0 the conversion script is now part of the transformers CLI "
"(**transformers-cli**) available in any transformers >= 2.3.0 "
"installation."
msgstr ""

#: ../../source/converting_tensorflow_models.rst:23
msgid ""
"The documentation below reflects the **transformers-cli convert** command"
" format."
msgstr ""

#: ../../source/converting_tensorflow_models.rst:26
msgid "BERT"
msgstr ""

#: ../../source/converting_tensorflow_models.rst:28
msgid ""
"You can convert any TensorFlow checkpoint for BERT (in particular `the "
"pre-trained models released by Google <https://github.com/google-"
"research/bert#pre-trained-models>`_\\ ) in a PyTorch save file by using "
"the :prefix_link:`convert_bert_original_tf_checkpoint_to_pytorch.py "
"<src/transformers/models/bert/convert_bert_original_tf_checkpoint_to_pytorch.py>`"
" script."
msgstr ""

#: ../../source/converting_tensorflow_models.rst:33
msgid ""
"This CLI takes as input a TensorFlow checkpoint (three files starting "
"with ``bert_model.ckpt``\\ ) and the associated configuration file (\\ "
"``bert_config.json``\\ ), and creates a PyTorch model for this "
"configuration, loads the weights from the TensorFlow checkpoint in the "
"PyTorch model and saves the resulting model in a standard PyTorch save "
"file that can be imported using ``from_pretrained()`` (see example in "
":doc:`quicktour` , :prefix_link:`run_glue.py <examples/pytorch/text-"
"classification/run_glue.py>` \\ )."
msgstr ""

#: ../../source/converting_tensorflow_models.rst:39
msgid ""
"You only need to run this conversion script **once** to get a PyTorch "
"model. You can then disregard the TensorFlow checkpoint (the three files "
"starting with ``bert_model.ckpt``\\ ) but be sure to keep the "
"configuration file (\\ ``bert_config.json``\\ ) and the vocabulary file "
"(\\ ``vocab.txt``\\ ) as these are needed for the PyTorch model too."
msgstr ""

#: ../../source/converting_tensorflow_models.rst:43
msgid ""
"To run this specific conversion script you will need to have TensorFlow "
"and PyTorch installed (\\ ``pip install tensorflow``\\ ). The rest of the"
" repository only requires PyTorch."
msgstr ""

#: ../../source/converting_tensorflow_models.rst:46
msgid ""
"Here is an example of the conversion process for a pre-trained ``BERT-"
"Base Uncased`` model:"
msgstr ""

#: ../../source/converting_tensorflow_models.rst:57
msgid ""
"You can download Google's pre-trained models for the conversion `here "
"<https://github.com/google-research/bert#pre-trained-models>`__."
msgstr ""

#: ../../source/converting_tensorflow_models.rst:61
msgid "ALBERT"
msgstr ""

#: ../../source/converting_tensorflow_models.rst:63
msgid ""
"Convert TensorFlow model checkpoints of ALBERT to PyTorch using the "
":prefix_link:`convert_albert_original_tf_checkpoint_to_pytorch.py "
"<src/transformers/models/albert/convert_albert_original_tf_checkpoint_to_pytorch.py>`"
" script."
msgstr ""

#: ../../source/converting_tensorflow_models.rst:67
msgid ""
"The CLI takes as input a TensorFlow checkpoint (three files starting with"
" ``model.ckpt-best``\\ ) and the accompanying configuration file (\\ "
"``albert_config.json``\\ ), then creates and saves a PyTorch model. To "
"run this conversion you will need to have TensorFlow and PyTorch "
"installed."
msgstr ""

#: ../../source/converting_tensorflow_models.rst:71
msgid ""
"Here is an example of the conversion process for the pre-trained ``ALBERT"
" Base`` model:"
msgstr ""

#: ../../source/converting_tensorflow_models.rst:82
msgid ""
"You can download Google's pre-trained models for the conversion `here "
"<https://github.com/google-research/albert#pre-trained-models>`__."
msgstr ""

#: ../../source/converting_tensorflow_models.rst:86
msgid "OpenAI GPT"
msgstr ""

#: ../../source/converting_tensorflow_models.rst:88
msgid ""
"Here is an example of the conversion process for a pre-trained OpenAI GPT"
" model, assuming that your NumPy checkpoint save as the same format than "
"OpenAI pretrained model (see `here <https://github.com/openai/finetune-"
"transformer-lm>`__\\ )"
msgstr ""

#: ../../source/converting_tensorflow_models.rst:104
msgid "OpenAI GPT-2"
msgstr ""

#: ../../source/converting_tensorflow_models.rst:106
msgid ""
"Here is an example of the conversion process for a pre-trained OpenAI "
"GPT-2 model (see `here <https://github.com/openai/gpt-2>`__\\ )"
msgstr ""

#: ../../source/converting_tensorflow_models.rst:120
msgid "Transformer-XL"
msgstr ""

#: ../../source/converting_tensorflow_models.rst:122
msgid ""
"Here is an example of the conversion process for a pre-trained "
"Transformer-XL model (see `here <https://github.com/kimiyoung"
"/transformer-xl/tree/master/tf#obtain-and-evaluate-pretrained-sota-"
"models>`__\\ )"
msgstr ""

#: ../../source/converting_tensorflow_models.rst:137
msgid "XLNet"
msgstr ""

#: ../../source/converting_tensorflow_models.rst:139
msgid ""
"Here is an example of the conversion process for a pre-trained XLNet "
"model:"
msgstr ""

#: ../../source/converting_tensorflow_models.rst:154
msgid "XLM"
msgstr ""

#: ../../source/converting_tensorflow_models.rst:156
msgid "Here is an example of the conversion process for a pre-trained XLM model:"
msgstr ""

#: ../../source/converting_tensorflow_models.rst:170
msgid "T5"
msgstr ""

#: ../../source/converting_tensorflow_models.rst:172
msgid "Here is an example of the conversion process for a pre-trained T5 model:"
msgstr ""

